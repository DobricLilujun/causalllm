{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uvicorn causal.text_generation_api:app --reload --host 127.0.0.1 --port 8889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llama/Personal_Directories/srb/causalEnv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain import PromptTemplate\n",
    "from utils.evaluate import calculate_cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "import subprocess\n",
    "import signal\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/Personal_Directories/srb/causalEnv/bin/python\n"
     ]
    }
   ],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the api is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The follwoing is ruuning: \n",
      "PID: 24290, Name: uvicorn, Command: /home/llama/Sandbox_IA/env/bin/python /home/llama/Sandbox_IA/env/bin/uvicorn app.main:app --reload --port 8001\n"
     ]
    }
   ],
   "source": [
    "def find_uvicorn_processes():\n",
    "    uvicorn_processes = []\n",
    "    for process in psutil.process_iter(['pid', 'name', 'cmdline']):\n",
    "        if 'uvicorn' in process.info['name'].lower() or \\\n",
    "                ('uvicorn' in process.info['cmdline'] if process.info['cmdline'] else False):\n",
    "            uvicorn_processes.append(process.info)\n",
    " \n",
    "    return uvicorn_processes\n",
    " \n",
    "def kill_process_by_pid(pid):\n",
    "    try:\n",
    "        process = psutil.Process(pid)\n",
    "        process.terminate()  # Alternatively, use process.kill() for a forceful termination\n",
    "        print(f\"Process {pid} has been terminated.\")\n",
    "    except psutil.NoSuchProcess:\n",
    "        print(f\"No process found with PID {pid}.\")\n",
    "\n",
    "uvicorn_processes = find_uvicorn_processes()\n",
    "\n",
    "if uvicorn_processes:\n",
    "    print(\"The follwoing is ruuning: \")\n",
    "    for process in uvicorn_processes:\n",
    "        print(f\"PID: {process['pid']}, Name: {process['name']}, Command: {' '.join(process['cmdline'])}\")\n",
    "else:\n",
    "    print(\"Uvicore unfound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the server using uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"causal\"\n",
    "module = \"text_generation_api_mixtral\"\n",
    "model = \"Mixtral_8_7B\"\n",
    "host = \"127.0.0.1\"\n",
    "port = 8899\n",
    "quantization = \"original\"\n",
    "python_executable = \"~/Personal_Directories/srb/causalEnv/bin/python\"\n",
    "test_num = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: '~/Personal_Directories/srb/causalEnv/bin/pyt...>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Will watch for changes in these directories: ['/home/llama/Personal_Directories/srb/causalllm-main']\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8899 (Press CTRL+C to quit)\n",
      "INFO:     Started reloader process [1219466] using StatReload\n",
      "Loading checkpoint shards:  53%|█████▎    | 10/19 [00:04<00:04,  2.07it/s]"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    " \n",
    "# %nohup run_uvicorn_command(directory, your_module, host,port)\n",
    "uvicorn_command = f\"{python_executable} -m uvicorn {directory}.{module}:app --reload --host {host} --port {port}\"\n",
    "subprocess.Popen(uvicorn_command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(input_string):\n",
    "    match = re.search(r'<Answer>(.*?)<\\/Answer>', input_string)\n",
    "    if match:\n",
    "        answer = match.group(1)\n",
    "        return answer, True\n",
    "    else:\n",
    "        return input_string, False  \n",
    "# answer,_ = extract_answer(input_string)\n",
    "# print(answer)\n",
    "\n",
    "# model_id = \"/home/llama/Personal_Directories/srb/causalllm-main/model/Llama-2-13b-chat-hf\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     model_id\n",
    "# )\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     trust_remote_code=True,\n",
    "#     device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define template\n",
    "system_prompt = \"\"\"\n",
    "Please strictly answer my question, but format it using custom tags like <Answer>Your answer here<Answer>. If the question cannot be answered, just answer with \"I don't know\". \n",
    "\"\"\"\n",
    "user_message = \"\"\"\n",
    "\n",
    "Instruction: Please strictly answer the question, but format it using custom tags like <Answer>Your answer here<Answer>. If the question cannot be answered, just answer with \"I don't know\". \n",
    "Context: Swift has won 12 Grammy Awards (including three for Album of the Year—tying for the most by an artist), an Emmy Award, 40 American Music Awards (the most won by an artist),29 Billboard Music Awards (the most won by a woman), 92 Guinness World Records, 14 MTV Video Music Awards (including three Video of the Year wins—the most by an act), 12 Country Music Association Awards (including the Pinnacle Award), eight Academy of Country Music Awards, and two Brit Awards. As a songwriter, she has been honored by the Nashville Songwriters Association, the Songwriters Hall of Fame, and the National Music Publishers' Association and was the youngest person on Rolling Stone's list of the 100 Greatest Songwriters of All Time in 2015. At the 64th BMI Awards in 2016, Swift was the first woman to be honored with an award named after its recipient. In 2023, Swift became the first act to be named the global best-selling artist of the year by the International Federation of the Phonographic Industry (IFPI) thrice.\n",
    "\n",
    "From available data, Swift has amassed over 50 million album sales, 150 million single sales, and 114 million units globally, including 78 billion streams. The International Federation of the Phonographic Industry (IFPI) ranked her as the Global Recording Artist of the Year for a record three times (2014, 2019 and 2022). Swift has the most number-one albums in the United Kingdom and Ireland for a female artist this millennium and earned the highest income for an artist on Chinese digital music platforms—RMB 159,000,000. Swift is the most streamed female act on Spotify, and the only artist to have received more than 200 million streams in one day (228 million streams on October 21, 2022).The most entries and the most simultaneous entries for an artist on the Billboard Global 200, with 94 and 31 songs, respectively, are among her feats. Her Reputation Stadium Tour (2018) is the highest-grossing North American tour ever, and she was the world's highest-grossing female touring act of the 2010s. Beginning with Fearless, all of her studio albums opened with over a million global units.\n",
    "Question: Given the passage below, tell me how many Grammy Awards, Emmy Awards, and Billboard Music Awards Taylor Swift has won and how many simultaneous entries she had on the Billboard Global 200 when she had the most simultaneous entries for an artist.\n",
    "\n",
    "\"\"\"\n",
    "template = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "{system_prompt}\n",
    "<</SYS>>\n",
    "\n",
    "{user_message} [/INST]\n",
    "\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "# prompt = prompt_template.format(\n",
    "#     system_prompt=system_prompt, user_message=user_message\n",
    "# )\n",
    "\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "# generated_ids = model.generate(\n",
    "#     **inputs\n",
    "# )\n",
    "\n",
    "# extract_answer(input_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"max_colwidth\", 1000)\n",
    "\n",
    "local_dataset_path = \"resource/data/databricks-dolly-15k\"\n",
    "dataset = load_from_disk(local_dataset_path)\n",
    "df = dataset.to_pandas()\n",
    "test_df = df[df[\"category\"] == \"closed_qa\"]\n",
    "test = test_df.head(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1219024/1791041859.py:47: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_df = pd.concat([result_df, pd.DataFrame([data])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:8899/generate-text\"\n",
    "system_prompt = \"\"\"\n",
    "Please strictly answer my question, but format it using custom tags like <Answer>Your answer here<Answer>. If the question cannot be answered, just answer with \"I don't know\". \"\"\"\n",
    "# template = \"\"\"\n",
    "# <s>[INST] <<SYS>>\n",
    "# {system_prompt}\n",
    "# <</SYS>>\n",
    "\n",
    "# Context: {context_message}\n",
    "# Question: {question_message}\n",
    "\n",
    "# [/INST]\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "Instruction:{system_prompt}\n",
    "Context: {context_message}\n",
    "Question: {question_message}\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "columns = [\n",
    "    \"temperature\",\n",
    "    \"model\",\n",
    "    \"ground_truth_response\",\n",
    "    \"prompt\"\n",
    "]\n",
    "result_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# build the preprocessed csv files\n",
    "for index, row in test.iterrows():\n",
    "    question = row[\"instruction\"]\n",
    "    context = row[\"context\"]\n",
    "    response = row[\"response\"]\n",
    "    prompt = prompt_template.format(\n",
    "        system_prompt=system_prompt, context_message=context, question_message = question\n",
    "    )\n",
    "\n",
    "    for temperature in np.arange(0.1, 2.0, 0.3):\n",
    "        data = {\n",
    "            \"temperature\": temperature,\n",
    "            \"model\": model,\n",
    "            \"ground_truth_response\": response,\n",
    "            \"prompt\": str(prompt),\n",
    "        }\n",
    "        result_df = pd.concat([result_df, pd.DataFrame([data])], ignore_index=True)\n",
    "\n",
    "\n",
    "result_df.to_excel(f\"{module}_{quantization}_{test_num}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_excel(f\"{module}_{quantization}_{test_num}.xlsx\")\n",
    "result_df[\"temperature\"] = result_df[\"temperature\"].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.huggingfaceUtil import generate_response_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2100 [00:05<2:56:56,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45634 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 2/2100 [00:10<2:57:09,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:49160 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 3/2100 [00:22<4:54:55,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:49174 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "WARNING:  StatReload detected changes in 'causal/text_generation_api_mixtral.py'. Reloading...\n",
      "INFO:     Shutting down\n",
      "  0%|          | 4/2100 [00:28<4:25:33,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:39220 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [1219468]\n",
      "Loading checkpoint shards: 100%|██████████| 19/19 [00:06<00:00,  2.86it/s]\n",
      "INFO:     Started server process [1220639]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 5/2100 [00:51<7:29:14, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:39224 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 6/2100 [00:57<6:10:25, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:41468 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 7/2100 [01:02<5:05:08,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:41472 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 8/2100 [01:10<4:58:41,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34480 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 9/2100 [01:21<5:25:58,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:54304 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 10/2100 [01:30<5:21:35,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:35354 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 11/2100 [01:42<5:48:47, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51142 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 12/2100 [01:53<6:00:58, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:52522 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 13/2100 [02:05<6:17:41, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:49896 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 14/2100 [02:17<6:28:08, 11.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38582 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 15/2100 [02:33<7:21:09, 12.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:56124 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 16/2100 [02:53<8:41:52, 15.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:41402 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 17/2100 [03:24<11:26:31, 19.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:57434 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 18/2100 [03:52<12:51:14, 22.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:37956 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 19/2100 [04:08<11:43:31, 20.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:56492 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 20/2100 [04:45<14:38:15, 25.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:46390 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 21/2100 [05:21<16:30:07, 28.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45706 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 22/2100 [05:31<13:14:25, 22.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:60326 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 23/2100 [05:41<11:04:26, 19.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:58166 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 24/2100 [05:52<9:34:25, 16.60s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:48416 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 25/2100 [06:08<9:28:15, 16.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:54680 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 26/2100 [06:29<10:12:49, 17.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:52216 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|▏         | 27/2100 [06:35<8:17:31, 14.40s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59860 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|▏         | 28/2100 [07:48<18:22:24, 31.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45176 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|▏         | 29/2100 [07:59<14:38:00, 25.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:55182 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|▏         | 30/2100 [08:09<11:58:52, 20.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51474 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|▏         | 31/2100 [08:19<10:06:56, 17.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:44400 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 32/2100 [08:29<8:48:42, 15.34s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34000 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 33/2100 [08:39<7:54:45, 13.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51302 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 34/2100 [09:23<13:06:53, 22.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:57658 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 35/2100 [10:28<20:19:16, 35.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45458 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 36/2100 [10:46<17:24:37, 30.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:57540 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 37/2100 [11:07<15:41:12, 27.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45668 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 38/2100 [11:19<13:05:03, 22.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:44594 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 39/2100 [11:40<12:41:20, 22.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:41906 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 40/2100 [11:57<11:52:47, 20.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:33136 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 41/2100 [12:42<16:05:09, 28.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:58558 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 42/2100 [13:57<24:03:22, 42.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:35028 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 43/2100 [14:37<23:37:27, 41.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:57298 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 44/2100 [15:39<27:09:18, 47.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:42820 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 45/2100 [16:17<25:29:58, 44.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:53028 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 46/2100 [17:16<28:05:36, 49.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38348 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 47/2100 [17:43<24:07:52, 42.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:42614 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 48/2100 [18:08<21:17:35, 37.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:60412 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 49/2100 [19:08<25:03:24, 43.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:58078 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 50/2100 [19:26<20:37:38, 36.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:39306 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 51/2100 [19:46<17:53:04, 31.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:47960 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 52/2100 [19:59<14:43:38, 25.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45758 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 53/2100 [20:39<17:10:36, 30.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:43798 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 54/2100 [21:29<20:29:16, 36.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:43540 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 55/2100 [22:00<19:31:24, 34.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45668 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 56/2100 [22:51<22:21:48, 39.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:60358 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 57/2100 [22:56<16:33:57, 29.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59908 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 58/2100 [23:01<12:27:48, 21.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59916 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 59/2100 [23:06<9:34:42, 16.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:50444 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 60/2100 [23:12<7:41:17, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:50446 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 61/2100 [23:19<6:34:44, 11.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:39478 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 62/2100 [23:27<5:57:02, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:39486 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 63/2100 [23:33<5:07:49,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:60016 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 64/2100 [23:46<5:48:21, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:43790 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 65/2100 [24:01<6:35:18, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:39658 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 66/2100 [24:22<8:11:44, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:41660 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 67/2100 [25:00<12:08:11, 21.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:54968 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 68/2100 [25:16<11:16:26, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:55980 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 69/2100 [25:29<10:09:16, 18.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59218 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 70/2100 [25:53<11:07:18, 19.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38952 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 71/2100 [26:04<9:34:42, 16.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:49598 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 72/2100 [26:15<8:34:08, 15.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:48436 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 73/2100 [26:21<7:04:33, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59742 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▎         | 74/2100 [26:30<6:22:45, 11.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:58588 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▎         | 75/2100 [26:41<6:24:12, 11.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:58600 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▎         | 76/2100 [26:58<7:22:43, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:39148 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▎         | 77/2100 [27:45<12:57:35, 23.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45446 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▎         | 78/2100 [28:15<14:07:54, 25.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:56798 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 79/2100 [28:34<13:07:08, 23.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:50054 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 80/2100 [29:02<13:49:41, 24.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38420 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 81/2100 [29:21<12:56:25, 23.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:33656 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 82/2100 [30:15<18:12:27, 32.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:47412 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 83/2100 [31:11<22:04:29, 39.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:58188 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 84/2100 [31:54<22:45:36, 40.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:52854 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 85/2100 [31:59<16:39:06, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:37950 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 86/2100 [32:03<12:17:16, 21.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:37956 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 87/2100 [32:11<10:00:57, 17.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:50760 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 88/2100 [32:20<8:25:20, 15.07s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45858 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 89/2100 [32:35<8:33:46, 15.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45870 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 90/2100 [32:44<7:30:15, 13.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:42682 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 91/2100 [32:49<6:00:04, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:57352 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 92/2100 [32:58<5:45:51, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:57360 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 93/2100 [33:14<6:35:40, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51402 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 94/2100 [33:21<5:53:41, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:58422 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 95/2100 [33:29<5:25:03,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:47772 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 96/2100 [34:16<11:39:40, 20.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:47780 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 97/2100 [35:03<16:01:07, 28.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:35466 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 98/2100 [35:14<12:57:24, 23.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45352 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 99/2100 [35:22<10:29:18, 18.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:33310 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 100/2100 [35:30<8:39:25, 15.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:47728 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 101/2100 [35:38<7:25:20, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:46216 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 102/2100 [35:49<6:55:35, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:46222 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 103/2100 [35:58<6:20:28, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45350 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 104/2100 [36:28<9:23:27, 16.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:56754 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 105/2100 [36:42<8:53:09, 16.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:39432 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 106/2100 [36:57<8:49:48, 15.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:48716 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 107/2100 [37:13<8:46:32, 15.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51398 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 108/2100 [37:28<8:37:50, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:37816 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 109/2100 [37:56<10:41:19, 19.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:50338 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 110/2100 [38:17<10:59:56, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:43534 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 111/2100 [38:47<12:43:05, 23.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:60448 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 112/2100 [39:42<17:58:12, 32.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:33958 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 113/2100 [39:47<13:17:06, 24.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59584 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 114/2100 [39:51<10:00:22, 18.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59596 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 115/2100 [39:56<7:55:23, 14.37s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:37090 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 116/2100 [40:03<6:40:50, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:37104 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 117/2100 [40:10<5:49:38, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:49402 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 118/2100 [40:17<5:09:58,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:42826 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 119/2100 [41:06<11:46:57, 21.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:42834 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 120/2100 [41:15<9:45:23, 17.74s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:48904 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 121/2100 [41:27<8:45:02, 15.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:37280 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 122/2100 [41:36<7:32:58, 13.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:43534 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 123/2100 [41:45<6:51:06, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:37400 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 124/2100 [42:15<9:37:06, 17.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:52954 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 125/2100 [42:22<7:57:58, 14.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:48288 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 126/2100 [43:11<13:31:59, 24.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:55052 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 127/2100 [43:42<14:40:36, 26.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:47762 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 128/2100 [44:14<15:25:27, 28.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:39620 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 129/2100 [44:45<15:56:17, 29.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:39450 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 130/2100 [45:29<18:19:26, 33.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:60036 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 131/2100 [45:55<17:06:10, 31.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:43562 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▋         | 132/2100 [46:41<19:33:33, 35.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:49088 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▋         | 133/2100 [47:27<21:15:29, 38.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45474 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▋         | 134/2100 [47:31<15:30:42, 28.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45710 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▋         | 135/2100 [47:35<11:29:26, 21.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38906 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▋         | 136/2100 [47:39<8:38:40, 15.85s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38920 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 137/2100 [47:43<6:40:40, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38922 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 138/2100 [47:48<5:32:17, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:52922 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 139/2100 [47:59<5:44:23, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:52924 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 140/2100 [48:03<4:37:06,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:46622 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 141/2100 [48:08<3:59:06,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:37138 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 142/2100 [48:12<3:32:23,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:37148 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 143/2100 [48:18<3:22:09,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59658 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 144/2100 [48:24<3:22:04,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:59666 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 145/2100 [48:29<3:14:33,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:55250 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 146/2100 [48:35<3:10:12,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:55266 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 147/2100 [48:42<3:23:22,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:37072 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 148/2100 [49:00<5:13:41,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:39924 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 149/2100 [49:09<5:09:43,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:32968 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 150/2100 [49:28<6:41:58, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:33744 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 151/2100 [49:36<6:04:34, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:55192 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 152/2100 [49:51<6:38:59, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:33680 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 153/2100 [50:37<12:00:44, 22.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:44984 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 154/2100 [50:54<11:16:03, 20.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:36022 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 155/2100 [50:59<8:44:28, 16.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:50550 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 156/2100 [51:05<6:58:06, 12.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:50552 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 157/2100 [51:10<5:44:43, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34326 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 158/2100 [51:15<4:52:39,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:36298 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 159/2100 [51:21<4:17:38,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:36300 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 160/2100 [51:29<4:14:57,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:40870 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 161/2100 [51:35<3:58:33,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:40880 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 162/2100 [51:40<3:34:50,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:53454 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 163/2100 [51:45<3:17:58,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:53462 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 164/2100 [51:50<3:07:16,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:36088 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 165/2100 [51:55<2:59:10,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:36096 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 166/2100 [52:11<4:39:50,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:36196 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 167/2100 [52:20<4:48:11,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34686 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 168/2100 [52:39<6:25:44, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:36048 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 169/2100 [52:46<5:39:16, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:60682 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 170/2100 [52:54<5:06:40,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34680 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 171/2100 [53:01<4:47:05,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:48798 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 172/2100 [53:08<4:28:44,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:40972 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 173/2100 [53:54<10:29:47, 19.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:40986 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 174/2100 [54:40<14:39:45, 27.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:54900 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 175/2100 [55:27<17:56:03, 33.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:45210 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 176/2100 [55:53<16:40:13, 31.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:33096 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 177/2100 [56:15<15:10:18, 28.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:55976 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 178/2100 [56:31<13:13:02, 24.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:46094 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|▊         | 179/2100 [56:57<13:20:42, 25.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:49512 - \"POST /generate-text HTTP/1.1\" 200 OK\n",
      "1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from utils.huggingfaceUtil import generate_response_hf\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time  # Import the time module\n",
    " \n",
    "csv_filename = f\"{module}_{quantization}_{test_num}.csv\"\n",
    "\n",
    "pbar = tqdm(total=len(result_df))\n",
    "\n",
    "responses = []\n",
    "\n",
    "similarities = []\n",
    " \n",
    "for index, row in result_df.iterrows():\n",
    "    start_time = time.time()  # Record the start time\n",
    "    response = generate_response_hf(row)\n",
    "    end_time = time.time()  # Record the end time\n",
    "    elapsed_time = end_time - start_time  # Calculate the elapsed time\n",
    "    updated_row = row.copy()\n",
    "    response_str = response[0][\"generated_text\"]\n",
    "    updated_row[\"full answer\"] = response_str\n",
    "    answer, label = extract_answer(response_str)\n",
    "    updated_row[\"generated_response\"] = answer\n",
    "    updated_row[\"label\"] = label\n",
    "    updated_row[\"elapsed_time\"] = elapsed_time  # Add elapsed time to the row\n",
    "    # Add the timestamp to the updated_row\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    updated_row[\"timestamp\"] = timestamp\n",
    "    updated_dataframe = pd.DataFrame([updated_row])\n",
    "    updated_dataframe.to_csv(csv_filename, index=False, mode=\"a\", header=not index)\n",
    "    pbar.update(1)\n",
    "    \n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
